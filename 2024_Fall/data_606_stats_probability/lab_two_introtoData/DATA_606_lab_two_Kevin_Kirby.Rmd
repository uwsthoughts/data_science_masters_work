---
title: "Introduction to data"
author: "Kevin Kirby"
output:
  pdf_document: default
  html_document:
    includes:
      in_header: header.html
    css: ./lab.css
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

Some define statistics as the field that focuses on turning information into knowledge. The first step in that process is to summarize and describe the raw information -- the data. In this lab we explore flights, specifically a random sample of domestic flights that departed from the three major New York City airports in 2013. We will generate simple graphical and numerical summaries of data on these flights and explore delay times. Since this is a large data set, along the way you'll also learn the indispensable skills of data processing and subsetting.


## Getting started

### Load packages

In this lab, we will explore and visualize the data using the **tidyverse** suite of packages. The data can be found in the companion package for OpenIntro labs, **openintro**.

Let's load the packages.

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
library(ggplot2)
```

### The data

The [Bureau of Transportation Statistics](http://www.rita.dot.gov/bts/about/) (BTS) is a statistical agency that is a part of the Research and Innovative Technology Administration (RITA). As its name implies, BTS collects and makes transportation data available, such as the flights data we will be working with in this lab.

First, we'll view the `nycflights` data frame. Type the following in your console to load the data:

```{r load-data}
data(nycflights)
```

The data set `nycflights` that shows up in your workspace is a *data matrix*, with each row representing an *observation* and each column representing a *variable*. R calls this data format a **data frame**, which is a term that will be used throughout the labs. For this data set, each *observation* is a single flight.

To view the names of the variables, type the command

```{r names}
names(nycflights)
```

This returns the names of the variables in this data frame. The **codebook** (description of the variables) can be accessed by pulling up the help file:

```{r help, eval=FALSE}
?nycflights
```

One of the variables refers to the carrier (i.e. airline) of the flight, which is coded according to the following system.

- `carrier`: Two letter carrier abbreviation.
    + `9E`:           Endeavor Air Inc.
    + `AA`:      American Airlines Inc.
    + `AS`:        Alaska Airlines Inc.
    + `B6`:             JetBlue Airways
    + `DL`:        Delta Air Lines Inc.
    + `EV`:    ExpressJet Airlines Inc.
    + `F9`:      Frontier Airlines Inc.
    + `FL`: AirTran Airways Corporation
    + `HA`:      Hawaiian Airlines Inc.
    + `MQ`:                   Envoy Air
    + `OO`:       SkyWest Airlines Inc.
    + `UA`:       United Air Lines Inc.
    + `US`:             US Airways Inc.
    + `VX`:              Virgin America
    + `WN`:      Southwest Airlines Co.
    + `YV`:          Mesa Airlines Inc.


Remember that you can use `glimpse` to take a quick peek at your data to understand its contents better.

```{r glimpse}
glimpse(nycflights)
```

The `nycflights` data frame is a massive trove of information. Let's think about some questions we might want to answer with these data:

- How delayed were flights that were headed to Los Angeles?
- How do departure delays vary by month?
- Which of the three major NYC airports has the best on time percentage for departing flights?


## Analysis


### Departure delays

Let's start by examing the distribution of departure delays of all flights with a histogram.

```{r hist-dep-delay}
ggplot(data = nycflights, aes(x = dep_delay)) +
  geom_histogram()
```

This function says to plot the `dep_delay` variable from the `nycflights` data frame on the x-axis. It also defines a `geom` (short for geometric object), which describes the type of plot you will produce. 

Histograms are generally a very good way to see the shape of a single distribution of numerical data, but that shape can change depending on how the data is split between the different bins. You can easily define the binwidth you want to use:

Kevin Note: I added the 300 one to more a more elongated chart so I could better understand what changes were happening.

```{r hist-dep-delay-bins}
ggplot(data = nycflights, aes(x = dep_delay)) +
  geom_histogram(binwidth = 15)
ggplot(data = nycflights, aes(x = dep_delay)) +
  geom_histogram(binwidth = 150)
ggplot(data = nycflights, aes(x = dep_delay)) +
  geom_histogram(binwidth = 300)

```


1.  Look carefully at these three histograms. How do they compare? Are features revealed in one that are obscured in another?

The first two charts are the best, where no bid width is specific or bins are set to 15. There's a long time and step pattern in the data as the departure delays get longer that are hidden from the 150 and 300 width I added. There's also an interesting shorter bar shown on the 15 minute's x axis below zero, suggesting a small number of early departures.The step pattern on the 150 width really makes me want to unpack the steps and see what's going on.  

If you want to visualize only on delays of flights headed to Los Angeles, you need to first `filter` the data for flights with that destination (`dest == "LAX"`) and then make a histogram of the departure delays of only those flights.

```{r lax-flights-hist}
lax_flights <- nycflights %>%
  filter(dest == "LAX")
ggplot(data = lax_flights, aes(x = dep_delay)) +
  geom_histogram()
```

Kevin Note: I don't like LA so I added a chart for Albuquerque, New Mexico because it reminded me of Breaking Bad, a very good TV show. Additionally, I suspected it would have a bit more chaotic of a chart since there are less flights there.

```{r abq-flights-hist}
abq_flights <- nycflights %>%
  filter(dest == "ABQ")
ggplot(data = abq_flights, aes(x = dep_delay)) +
  geom_histogram()
```

Let's decipher these two commands (OK, so it might look like four lines, but the first two physical lines of code are actually part of the same command. It's common to add a break to a new line after `%>%` to help readability).

- Command 1: Take the `nycflights` data frame, `filter` for flights headed to LAX, and save the result as a new data frame called `lax_flights`.
    + `==` means "if it's equal to".
    + `LAX` is in quotation marks since it is a character string.
- Command 2: Basically the same `ggplot` call from earlier for making a histogram, except that it uses the smaller data frame for flights headed to LAX instead of all flights.

<div id="boxedtext">
**Logical operators: ** Filtering for certain observations (e.g. flights from a particular airport) is often of interest in data frames where we might want to examine observations with certain characteristics separately from the rest of the data. To do so, you can use the `filter` function and a series of **logical operators**. The most commonly used logical operators for data analysis are as follows:

- `==` means "equal to"
- `!=` means "not equal to"
- `>` or `<` means "greater than" or "less than"
- `>=` or `<=` means "greater than or equal to" or "less than or equal to"
</div>

You can also obtain numerical summaries for these flights:

```{r lax-flights-summ}
lax_flights %>%
  summarise(mean_lax   = mean(dep_delay), 
            median_lax = median(dep_delay), 
            iqr_lax = IQR(dep_delay),
            n         = n())
```

Kevin Note: adding same stats for ABQ since I'm committed to the bit. I also added some other summary stats I wanted to see for both LA and ABQ. 

```{r abq-flights-summ}
abq_flights %>%
  summarise(mean_abq   = mean(dep_delay), 
            median_abq = median(dep_delay), 
            iqr_aqb = IQR(dep_delay),
            n         = n())
```


Note that in the `summarise` function you created a list of three different numerical summaries that you were interested in. The names of these elements are user defined, like `mean_dd`, `median_dd`, `n`, and you can customize these names as you like (just don't use spaces in your names). Calculating these summary statistics also requires that you know the function calls. Note that `n()` reports the sample size.

<div id="boxedtext">
**Summary statistics: ** Some useful function calls for summary statistics for a single numerical variable are as follows:

- `mean`
- `median`
- `sd`
- `var`
- `IQR`
- `min`
- `max`

Note that each of these functions takes a single vector as an argument and returns a single value. 
</div>

You can also filter based on multiple criteria. Suppose you are interested in flights headed to San Francisco (SFO) in February:

```{r sfo-feb-flights}
sfo_feb_flights <- nycflights %>%
  filter(dest == "SFO", month == 2)
```

Kevin Note: as a boy from Maine, I'm going somewhere very warm in February so here's Miami:

```{r mia-feb-flights}
mia_feb_flights <- nycflights %>%
  filter(dest == "MIA", month == 2)
```

Note that you can separate the conditions using commas if you want flights that are both headed to SFO **and** in February. If you are interested in either flights headed to SFO **or** in February, you can use the `|` instead of the comma.

2.  Create a new data frame that includes flights headed to SFO in February, 
    and save this data frame as `sfo_feb_flights`. How many flights 
    meet these criteria? 

This is a copy of above code chunk for convenience of having the answer in one spot. In addition, I added the glimpse function so I could see row count. There are 68 rows in the subset, which means 68 flights meet the criteria. 
```{r sfo-feb-flights-2}
sfo_feb_flights <- nycflights %>%
  filter(dest == "SFO", month == 2)
glimpse(sfo_feb_flights)
```

3.  Describe the distribution of the **arrival** delays of these flights using a 
    histogram and appropriate summary statistics. **Hint:** The summary 
    statistics you use should depend on the shape of the distribution.
 
First, let's create the histogram:
```{r sfo-feb-delays}
sfo_feb_flights %>%
  ggplot(aes(x = arr_delay)) + 
  geom_histogram()
```

Based on this distribution, I would Like to know:

* Median: There's a lot of negative values and I would like to see where the median in. The presence of the outlier at 200 minutes on a small subset like this means the mean will be dragged higher. I'm going to add mean anyway for reference.
*Variance: the awkardly distributed tails extending out to the right means there's probably a high variance.
*Interquartile Range: I'm expecting the middle 50% to be relatively small, maybe under 30 minutes. 

```{r sfofeb-stats}
sfo_feb_flights %>%
  summarise(mean_sfofeb   = mean(arr_delay), 
            median_sfofeb = median(arr_delay), 
            iqr_sfofeb = IQR(arr_delay),
            var_sfofeb = var(arr_delay),
            n_sfofed  =   n())
```

The distribution is bottom heavy, with a larger than expected number of negative values. Both New York and San Francisco are busy and delayed airports so I would expect more delayed arrivals.However, the airlines have gotten a lot better at padding flight times so, relative to when they officially say they will arrive, they get there early.

The mean is being dragged upwards by the 200 minute delayed flight, which is also causing a high variance. I would describe the overall distribution as normal-ish. I suspect, if there were more data points available, you would see the tail out towards 100 fill out a bit more. That 200 one would remain an outlier and, in future analysis, would need to be handled. 

Another useful technique is quickly calculating summary statistics for various groups in your data frame. For example, we can modify the above command using the `group_by` function to get the same summary stats for each origin airport:

```{r summary-custom-list-origin}
sfo_feb_flights %>%
  group_by(origin) %>%
  summarise(median_dd = median(dep_delay), iqr_dd = IQR(dep_delay), n_flights = n())
```

Here, we first grouped the data by `origin` and then calculated the summary statistics.

4.  Calculate the median and interquartile range for `arr_delay`s of flights in
    in the `sfo_feb_flights` data frame, grouped by carrier. Which carrier
    has the most variable arrival delays?
    
First, I'll calculate the required stats and also include a sort by largest mechanism on n_flights so the airline with the most values rises to the top.

```{r summary-sfofeb-delays}
sfo_feb_flights %>%
  group_by(carrier) %>%
  summarise(median_dd = median(arr_delay), 
            iqr_dd = IQR(arr_delay), 
            n_flights = n()) %>%
  arrange(desc(n_flights))
```

The winner is United Airlines, with 21. This a function of United having a hub in SFO and, therefore, a higher number of flights there than most. In addition, another one of their hubs in EWR and one of their most common routes is EWR to SFO. 

### Departure delays by month

Which month would you expect to have the highest average delay departing from an NYC airport?

Let's think about how you could answer this question:

- First, calculate monthly averages for departure delays. With the new language you are learning, you could
    + `group_by` months, then
    + `summarise` mean departure delays.
- Then, you could to `arrange` these average delays in `desc`ending order

Kevin Note: I added a bar chart that invokes "identity" for stat to allow me to see see the mean data as a regular bar chart.
```{r mean-dep-delay-months}
mean_delay_by_month <- nycflights %>%
  group_by(month) %>%
  summarise(mean_dd = mean(dep_delay, na.rm = TRUE)) %>%
  arrange(desc(mean_dd))

ggplot(mean_delay_by_month, aes(x = month, y = mean_dd)) +
  geom_bar(stat = "identity") 
```

Kevin Note: the summer months of Junr and July and the holiday month of February being at the top isn't surprising and is more in the "that was predictable" end of the spectrum rather than "huh, that's surprising. 

5.  Suppose you really dislike departure delays and you want to schedule 
    your travel in a month that minimizes your potential departure delay leaving 
    NYC. One option is to choose the month with the lowest mean departure delay.
    Another option is to choose the month with the lowest median departure delay. 
    What are the pros and cons of these two choices?

* Mean
  * Pros
    *This could better represent the chance for an outlier experience since all values would be taken into account
    * It would work best for normally distributed data without an excessive tail. Excessive tails drag means up, which famously happens in housing prices
  *Cons
    * The mean is really just a medicore metric with limited value by itself and shouldn't usually be the basis for a decision. It can be easily warped by outliers and, if you're traveling, you want something closer to the middle of the dataset

Median
  * Pros
    * The median is the middle, which means you have a heavy clutestering of the number of values around it. You would have a higher liklihood, as a percent of number of flights, of having a departure delay near it
  * Cons
    * It doesn't adapt to changes in the values of the data until the whole set has moved enough to move the middle
  

### On time departure rate for NYC airports

Suppose you will be flying out of NYC and want to know which of the three major NYC airports has the best on time departure rate of departing flights. Also supposed that for you, a flight that is delayed for less than 5 minutes is basically "on time."" You consider any flight delayed for 5 minutes of more to be "delayed".

In order to determine which airport has the best on time departure rate, you can 

- first classify each flight as "on time" or "delayed",
- then group flights by origin airport,
- then calculate on time departure rates for each origin airport,
- and finally arrange the airports in descending order for on time departure percentage.

Let's start with classifying each flight as "on time" or "delayed" by creating a new variable with the `mutate` function.

```{r dep-type}
nycflights <- nycflights %>%
  mutate(dep_type = ifelse(dep_delay < 5, "on time", "delayed"))
```


The first argument in the `mutate` function is the name of the new variable we want to create, in this case `dep_type`. Then if `dep_delay < 5`, we classify the flight as `"on time"` and `"delayed"` if not, i.e. if the flight is delayed for 5 or more minutes.

Note that we are also overwriting the `nycflights` data frame with the new version of this data frame that includes the new `dep_type` variable.

We can handle all of the remaining steps in one code chunk:

```{r ot-dep-rate}
nycflights %>%
  group_by(origin) %>%
  summarise(ot_dep_rate = sum(dep_type == "on time") / n()) %>%
  arrange(desc(ot_dep_rate))
```

6.  If you were selecting an airport simply based on on time departure percentage, which NYC airport would you choose to fly out of?


You can also visualize the distribution of on on time departure rate across the three airports using a segmented bar plot.

```{r viz-origin-dep-type}
ggplot(data = nycflights, aes(x = origin, fill = dep_type)) +
  geom_bar()
```

LGA is the technically correct answer at 72.8% on time but not the context correct answer. LGA has flight distance restrictions, which means airlines can only have flights that extend as far west as Denver fly out of it. This also means it can't have international flights except to certain spots in Europe. There are a subset of flights that happen at all three and I, as a citizen of NYC, always pick LGA when it's an option for a nonstop flight. 

* * *

## More Practice

7.  Mutate the data frame so that it includes a new variable that contains the 
    average speed, `avg_speed` traveled by the plane for each flight (in mph).
    **Hint:** Average speed can be calculated as distance divided by
    number of hours of travel, and note that `air_time` is given in minutes.
 
Here's how to do the mutation. I added air_time_hours, which just divides air_time hours by 60 to get hours. Then I added avg_speed, which can now be simple division of distance/air_time hours. This provides average distance as a function of flight hours.


```{r avg_speed}
nycflights <- nycflights %>%
  mutate(air_time_hours = air_time / 60) %>%
  mutate(avg_speed = distance / air_time_hours)
```


8.  Make a scatterplot of `avg_speed` vs. `distance`. Describe the relationship
    between average speed and distance.
    **Hint:** Use `geom_point()`.

```{r avgspeed-scatter}

ggplot(nycflights, aes(x = distance, y = avg_speed)) +
  geom_point(color = "blue")

```

I didn't find that scatter particularly insightful so I tried adding a geom_bid_2d() chart, which is a scatter plot with a heat map built in. Admittedly, it's a bit of an ugly blob that shows what you could guess: the most density of flights is around 500-525 MPH. 

```{r alternative-scatter}

ggplot(nycflights, aes(x = distance, y = avg_speed)) +
  geom_bin_2d()

```

9.  Replicate the following plot. **Hint:** The data frame plotted only
    contains flights from American Airlines, Delta Airlines, and United
    Airlines, and the points are `color`ed by `carrier`. Once you replicate
    the plot, determine (roughly) what the cutoff point is for departure
    delays where you can still expect to get to your destination on time.

```{r plot-to-replicate, echo=FALSE}
knitr::include_graphics("/Users/kevinkirby/Desktop/question-9-image.png")
```


```{r scatter-by-airlines}

scatter_subset_airlines <- nycflights %>%
  filter(carrier %in% c("UA", "AA", "DL"))

ggplot(scatter_subset_airlines, aes(x = dep_delay, y = arr_delay, color = carrier)) +
  geom_point() +
  scale_color_manual(values = c("UA" = "skyblue2", "AA" = "pink", "DL" = "green")) +
  labs(title = "Scatter Plot of Arrival vs Departure Delays by Airline",
       x = "Departure Delay",
       y = "Arrival Delay",
       color = "Carrier") +
  theme_minimal()

```

For the purpose of answering this question, I assumed what really mattered was a flight arriving within five minutes of scheduled arrival. It's sort if like cool story, bro if your flight departs on time and is still an hour late, which a lot of these flights are. Based on the chart, if you're flight departs no more than five minutes late then you can expect your flight to arrive within five minutes of scheduled arrival.

However, using a chart like this to answer this question is suboptimal. Why do "roughly" when you can just produce some numbers to go along with it. Here I make summary stats by airline and then overall, based on a new dataframe that's filtered for arriving withi five minutes.

This shows you the mean, median, minimum, and maximum departure delays you can have by airline and still arrive within five minutes. When combined with the scatter plot, you can understand the numbers on a deeper level and figure out what risk you're willing to take. 

```{r-new-arrival-stats}

five_min_subset <- scatter_subset_airlines %>%
  filter(arr_delay <= 5)

stats_airline <- five_min_subset %>%
  group_by(carrier) %>%
  summarise(mean_dep_delay_a = mean(dep_delay, na.rm = TRUE),
            median_dep_delay_a = median(dep_delay, na.rm = TRUE),
            min_dep_delay_a = min(dep_delay, na.rm = TRUE),
            max_dep_delay_a = max(dep_delay, na.rm = TRUE),
            n_airline = n())

stats_airline

```


As you can see from the overall stats, you really have to have a flight that leaves ahead of schedule to have a reasonable chance of getting to your destination within five minutes. And that, really, is the American flying experience. 

```{r-overall-delay-stats}

overall_fivemin <- five_min_subset %>%
  summarise(mean_dep_delay_o = mean(dep_delay, na.rm = TRUE),
            median_dep_delay_o = median(dep_delay, na.rm = TRUE),
            min_dep_delay_o = min(dep_delay, na.rm = TRUE),
            max_dep_delay_o = max(dep_delay, na.rm = TRUE),
            n_overall = n())

overall_fivemin

```
